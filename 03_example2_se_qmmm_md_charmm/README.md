# Umbrella Sampling with QM/MM in CHARMM49-mndo97 from CHARMM-GUI QM/MM Interfacer Template Files
##### These instructions are for running umbrella sampling simulations using QM/MM in CHARMM49-mndo97, starting from CHARMM-GUI QM/MM Interfacer template files.

### 1.1. Inspect the pdb file from the template files generated by CHARMM-GUI QM/MM Interfacer in your local/personal machine
```bash
conda activate pymolvmdenv
tar -xvzf charmm-gui.tgz
cd charmm-gui-*/charmm
pymol step3_input.pdb
```
- **Note down the "segi, resi, name" of atoms to be restrained in umbrella sampling simulations FROM PyMOL.**<p>
```bash
# Make the selection by atom from top-menu in PyMOL
-  Mouse -> Selection Mode -> Atoms

# Click only the donor carbon atom make the selection 'sele'
PyMOL> iterate_state 1, sele, print(segi, resi, name, ID)
PyMOL> deselect # Deselect the selection before making the next selection

# Click only the hydride atom make the selection 'sele'
PyMOL> iterate_state 1, sele, print(segi, resi, name, ID)
PyMOL> deselect # Deselect the selection before making the next selection

# Click only the acceptor carbon atom make the selection 'sele'
PyMOL> iterate_state 1, sele, print(segi, resi, name, ID)
PyMOL> deselect # Deselect the selection before making the next selection

# Example outputs for each iterate_state command (Note the ID of the atoms for umbrella sampling):
# HETD 1 C19 2681 # for donor carbon atom
# HETD 1 H26 2683 # for hydide atom
# HETB 1 C4 2577 # fo acceptor carbon atom
```
### 1.2. Modify the 'step5_production.inp' file to include the umbrella sampling restraints
```bash
nano step5_production.inp
```
- **Modifications where made to umbrella sampling specifications amd restart file**<p>

### 1.3. Copy the control bash Script to the working directory in the remote machine
```bash
cd charmm-gui-*/charmm
wget <github link>
```

### 2.1. Make a working directory for simulation on the remote machine
```bash
cd icomse_knam_session
mkdir ex1_charmm_seqmmm
```

### 2.2 Copy the CHARMM-GUI QM/MM Interfacer template files to the working directory in the remote machine
- **execute the command from local/personal machine**
```bash
scp -r <extracted_charmm_gui_folder_after_modification> <username>@<remote_machine>:/path/to/icomse_knam_session/ex2_charmm_seqmmm
```

### 3 Inspect the README_UMB_CHARMM.sh 
- **Modify the bash control file for running MM minimization, MM equilibration and QM/MM sweeping in the remote machine**
```bash
nano README_UMB_CHARMM.sh
```
- **Modifications**<p>
```bash
..
..
# Activate your conda environment
# replace <your_username> with your actual username to set path correctly
eval "$(/scratch/<your_username>/icomse_knam_session/miniconda3/bin/conda shell.bash hook)"
conda activate knamsessionenv
module load openmpi-5.0.5 # load the openmpi=5 module available on the remote machine
..
..
# Set executable
charmm="mpirun -np 12 /scratch/<user_name>/icomse_knam_session/charmm/install_charmm/bin/charmm" # replace <user_name> with your actual username to set path correctly
..
..
# Reaction Specs
rci=-2.0 #initial
rcf=2.0  #final
rcdel=0.1
kmin=150 #20
kmax=150
..
..
win=1 #CHANGE HERE IF COUNTINUING STARTING WINDOW
#winmax=${win} #UNCOMMENT IF RUNNING ONLY ONE WINDOW 
icnt=1  #CHANGE HERE IF COUNTINUING A RUN AT SPECIFIC COUNTER IN ${win}
cntmax=1 #MAXIMUM NUMBER OF CHUNKS PER WINDOW
..
..
```
### 4. Run the bash control file in the remote machine for running MM minimization, MM equilibration and QM/MM sweeping
```bash
cd icomse_knam_session/ex1_amber_seqmmm/charmm-gui-*/charmm
nohup ./README_UMB_CHARMM.sh > README_UMB_CHARMM.log 2>&1
```
- **If using SLURM, Note**: If you are running this on a remote machine with a job scheduler like SLURM, you can create a SLURM script to submit the job. See the example below for file name 'submit_umb_amber.slurm'.
```bash
nano submit_umb_charmm.slurm
```
- **Example SLURM script**<p>
```bash
#IF SLURM JOB MAKE A slurm script like this:
#!/bin/bash
#SBATCH --job-name=umb_charmm_mpi
#SBATCH --output=README_UMB_CHARMM.log
#SBATCH --error=README_UMB_CHARMM.log
#SBATCH --ntasks=12                 # 12 MPI ranks (used by mpirun)
#SBATCH --cpus-per-task=1          # 1 core per MPI rank
#SBATCH --time=48:00:00
#SBATCH --mem=4G                   # Adjust if needed per task or node
#SBATCH --partition=standard

# Navigate to simulation folder, set the path correctly
cd $SCRATCH/icomse_knam_session/ex2_charmm_seqmmm/charmm-gui-*/charmm

# Run the CHARMM-GUI umbrella sampling script
bash ./README_UMB_AMBER.sh
``` 
- **Submit the SLURM job**:
```bash
sbatch submit_umb_charmm.slurm
```
### 5. Run Production QM/MM MD simulation for each window independently on the remote machine
- **After the sweeping simulation, we have restart file for each window. We can run production QM/MM MD simulation for each window independently.**<p>
```bash
cd icomse_knam_session/ex2_charmm_seqmmm/charmm-gui-*/charmm
```
- **Modify the 'README_PROD_CHARMM.sh' file for production QM/MM MD simulation**<p>
```bash
nano README_PROD_CHARMM.sh
```
- **Modifications**<p>
```bash
..
..
# Set executable
charmm="mpirun -np 12 /scratch/<user_name>/icomse_knam_session/charmm/install_charmm/bin/charmm" # replace <user_name> with your actual username to set path correctly
..
..
# Equilibration
#$charmm < "${equi_prefix}.inp" > "${equi_prefix}.out"
#
# QM/MM input preparation
#$charmm < "${qmpr_prefix}.inp" > "${qmpr_prefix}.out"
..
..
# Reaction Specs
rci=-2.0 #initial
rcf=2.0  #final
rcdel=0.1
kmin=40 #gradually increase the kmin value for production run and peaks at rc=0 
kmax=150
..
..
win=$1 #CHANGE HERE IF COUNTINUING STARTING WINDOW
winmax=${win} #UNCOMMENT IF RUNNING ONLY ONE WINDOW 
icnt=2  #CHANGE HERE IF COUNTINUING A RUN AT SPECIFIC COUNTER IN ${win}
cntmax=5 #MAXIMUM NUMBER OF CHUNKS PER WINDOW
..
..
```
### 6. Run the bash control file in the remote machine for running production QM/MM MD simulation
```bash
cd icomse_knam_session/ex2_charmm_seqmmm/charmm-gui-*/charmm
nohup ./README_PROD_CHARMM.sh 1 > README_PROD_CHARMM.log 2>&1
nohup ./README_PROD_CHARMM.sh 2 > README_PROD_CHARMM.log 2>&1
nohup ./README_PROD_CHARMM.sh 3 > README_PROD_CHARMM.log 2>&1
..
..
```
- **If using SLURM, Note**: If you are running this on a remote machine with a job scheduler like SLURM, you can create a SLURM script to submit the job. See the example below for file name 'submit_prod_charmm.slurm'.
```bash
mkdir -p slurm_logs
nano submit_prod_charmm.slurm
```
- **Example SLURM script**<p>
```bash
#!/bin/bash
#SBATCH --job-name=prod_charmm_mpi
#SBATCH --output=slurm_logs/prod_window_%A_%a.out
#SBATCH --error=slurm_logs/prod_window_%A_%a.err
#SBATCH --ntasks=8
#SBATCH --cpus-per-task=1
#SBATCH --time=48:00:00
#SBATCH --mem=4G
#SBATCH --partition=standard
#SBATCH --array=1-41    # Adjust based on total number of windows

# Load conda + environment (only if not already done inside the .sh)
# module load anaconda
# source $(conda info --base)/etc/profile.d/conda.sh
# conda activate knamsessionenv

# Navigate to simulation directory
cd $SCRATCH/icomse_knam_session/ex2_charmm_seqmmm/charmm-gui-*/charmm

# SLURM_ARRAY_TASK_ID will be used as window number
win=${SLURM_ARRAY_TASK_ID}

# Run CHARMM-GUI-generated umbrella sampling production for this window
bash ./README_PROD_CHARMM.sh $win
```
- **Submit the SLURM job**:
```bash
sbatch submit_prod_charmm.slurm
```
